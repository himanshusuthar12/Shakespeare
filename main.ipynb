{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "l4UP4m5kQ-ij"
      },
      "outputs": [],
      "source": [
        "# !pip install tensorflow\n",
        "# !pip install numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "P1znr4-qPL4K"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import string\n",
        "import os\n",
        "import pickle\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_gwKye49PS-a"
      },
      "source": [
        "Load & Preprocess Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "QoCQinXmPNke"
      },
      "outputs": [],
      "source": [
        "DATA_PATH = \"/content/shakespeare.txt\"\n",
        "CHECKPOINT_PATH = \"best_lstm_text_model.keras\"\n",
        "SEED = 42\n",
        "SEQ_LENGTH = 100\n",
        "STEP = 1\n",
        "\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)\n",
        "\n",
        "if not os.path.exists(DATA_PATH):\n",
        "    raise FileNotFoundError(\n",
        "        f\"Dataset not found at {DATA_PATH}. Place shakespeare.txt in the project folder.\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "fmCStJQhPNl8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc995a51-91d7-4d83-ed53-f7173836ea80"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total characters: 5128224\n"
          ]
        }
      ],
      "source": [
        "with open(DATA_PATH, \"r\", encoding=\"utf-8\") as f:\n",
        "    text = f.read()\n",
        "\n",
        "text = text.lower()\n",
        "\n",
        "# Remove punctuation\n",
        "text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
        "\n",
        "print(f\"Total characters: {len(text)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "-M6CGHWEPNqC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c3d77eb-30aa-4e5c-b46e-dc6ab6801154"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary size: 56\n"
          ]
        }
      ],
      "source": [
        "# Character-level tokenization\n",
        "chars = sorted(list(set(text)))\n",
        "vocab_size = len(chars)\n",
        "\n",
        "print(f\"Vocabulary size: {vocab_size}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "_CQjz_WtPNrp"
      },
      "outputs": [],
      "source": [
        "# Create char-to-index mappings\n",
        "char_to_idx = {char: idx for idx, char in enumerate(chars)}\n",
        "idx_to_char = {idx: char for idx, char in enumerate(chars)}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BFQq3IkKPr0R"
      },
      "source": [
        "Create Sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lnIyhndRPNvP",
        "outputId": "7b16f628-3dcf-46d4-a91f-f134a048b319"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of sequences: 5128124\n"
          ]
        }
      ],
      "source": [
        "input_sequences = []\n",
        "target_chars = []\n",
        "\n",
        "for i in range(0, len(text) - SEQ_LENGTH, STEP):\n",
        "    input_sequences.append(text[i:i + SEQ_LENGTH])\n",
        "    target_chars.append(text[i + SEQ_LENGTH])\n",
        "\n",
        "print(f\"Number of sequences: {len(input_sequences)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "I7VP-d2xPvLC"
      },
      "outputs": [],
      "source": [
        "# Convert sequences to numerical form\n",
        "X = np.zeros((len(input_sequences), SEQ_LENGTH), dtype=np.int32)\n",
        "y = np.zeros((len(input_sequences)), dtype=np.int32)\n",
        "\n",
        "for i, seq in enumerate(input_sequences):\n",
        "    X[i] = [char_to_idx[char] for char in seq]\n",
        "    y[i] = char_to_idx[target_chars[i]]\n",
        "\n",
        "# Shuffle before split to reduce bias\n",
        "perm = np.random.permutation(len(X))\n",
        "X = X[perm]\n",
        "y = y[perm]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3fiPkpLrP0vy"
      },
      "source": [
        " Train / Validation Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "eAD9Rx5VPvM9"
      },
      "outputs": [],
      "source": [
        "split_idx = int(0.9 * len(X))\n",
        "X_train, X_val = X[:split_idx], X[split_idx:]\n",
        "y_train, y_val = y[:split_idx], y[split_idx:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HHhgfym2P6Gy"
      },
      "source": [
        "Build LSTM Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "JdwQ1Vz-PvQc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f69d6ea-95bd-48d9-e8e5-fadd25cc6d64"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "model = Sequential([\n",
        "    Embedding(input_dim=vocab_size, output_dim=128, input_length=SEQ_LENGTH),\n",
        "    LSTM(256, return_sequences=True),\n",
        "    LSTM(256),\n",
        "    Dense(vocab_size, activation=\"softmax\")\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "bo146hGMPvTT"
      },
      "outputs": [],
      "source": [
        "model.compile(\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    optimizer=\"adam\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "jGmLBi9bPvWR"
      },
      "outputs": [],
      "source": [
        "# model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yrfbConeQHwK"
      },
      "source": [
        "Train Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "8EtXSKvjPvX4"
      },
      "outputs": [],
      "source": [
        "callbacks = [ EarlyStopping(monitor=\"val_loss\", patience=3, restore_best_weights=True), ModelCheckpoint(CHECKPOINT_PATH, save_best_only=True)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "NrorNkxvPvc-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9935cc70-0952-4d26-cb21-fde6f04373db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m36058/36058\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1178s\u001b[0m 33ms/step - loss: 1.7316 - val_loss: 1.3875\n"
          ]
        }
      ],
      "source": [
        "history = model.fit( X_train, y_train, validation_data=(X_val, y_val), epochs=1, batch_size=128, callbacks=callbacks)                # Its take training too much time so am use epochs = 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3HY_3kNdQY4_"
      },
      "source": [
        "Text Generation Logic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "Avklvfe9PNw6"
      },
      "outputs": [],
      "source": [
        "\n",
        "if os.path.exists(CHECKPOINT_PATH):\n",
        "    model.load_weights(CHECKPOINT_PATH)\n",
        "\n",
        "def _prepare_seed(seed_text):\n",
        "    seed = seed_text.lower()\n",
        "    if len(seed) < SEQ_LENGTH:\n",
        "        pad_char = \" \" if \" \" in char_to_idx else list(char_to_idx.keys())[0]\n",
        "        seed = (pad_char * (SEQ_LENGTH - len(seed))) + seed\n",
        "    return seed\n",
        "\n",
        "def generate_text(seed_text, length=500, temperature=0.8):\n",
        "    generated = _prepare_seed(seed_text)\n",
        "\n",
        "    for _ in range(length):\n",
        "        input_seq = generated[-SEQ_LENGTH:]\n",
        "        input_idx = np.array([[char_to_idx.get(c, 0) for c in input_seq]])\n",
        "\n",
        "        preds = model.predict(input_idx, verbose=0)[0]\n",
        "\n",
        "        preds = np.log(preds + 1e-8) / max(temperature, 1e-3)\n",
        "        probs = np.exp(preds) / np.sum(np.exp(preds))\n",
        "\n",
        "        next_idx = np.random.choice(len(probs), p=probs)\n",
        "        generated += idx_to_char[next_idx]\n",
        "\n",
        "    return generated"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6CFreXtyQhVj"
      },
      "source": [
        "Generate Sample Text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "cf0OB8poPN1O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09dd3540-1712-4000-f967-932a2003e5b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                             to be or not to be that is the question\n",
            "shall equal and in the people of our hortens it is a man tell them\n",
            "\n",
            "lucibiales\n",
            "and doth he lives well he will tell you they made then\n",
            "what is his brow\n",
            "\n",
            "grumio\n",
            "run out bear and marriage\n",
            "\n",
            "camillo\n",
            "sir that play in master germies\n",
            "and the sun you that they are made destised train by foul sir betwixt eye about a traitor of any good you have you father of the world of my tears and three war into so may \n"
          ]
        }
      ],
      "source": [
        "seed = \"to be or not to be that is the question\"\n",
        "print(generate_text(seed, 400))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K_-KvKsmQe3Y",
        "outputId": "ba3162d8-f8eb-4ad1-bc12-270742286fa2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                              my lord i do protest too much methinks to find\n",
            "the fond wars a hope of her first\n",
            "as i be cirching or with somectors nor that the vicer his salisbury\n",
            "\n",
            "helena\n",
            "they mean should be the weapons a worthy letter the guilty\n",
            "\n",
            "exeunt\n",
            "\n",
            "caesar\n",
            "and he way what was more tiglary\n",
            "\n",
            "marcellus\n",
            "i that i am behind to prosper upon this wife\n",
            "\n",
            "bolingbroke\n",
            "no come my lord friends and his bear a sail of him\n",
            "\n",
            "dromio of my down\n",
            "why receive me the conquess be to \n"
          ]
        }
      ],
      "source": [
        "seed = \"my lord i do protest too much methinks\"\n",
        "print(generate_text(seed, 400))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "jfU3TZMCQe5n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d14789a-7a2a-4654-c67e-ddbbde48ae49"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                    all the worlds a stage and all the men and women to more be a wise it is the bitterweent\n",
            "\n",
            "she doth she hadst my touch like a jest will i all chamberlain that thou couldst romeo thine in the contrary will cannot be what nor i for the enemy\n",
            "pointed of my brother that we wilt thou shalt make thee to too\n",
            "but warrant the murderers like a strife bewells my father is no catch\n",
            "his undovenigence of york be ear that while yet not the sands hath wronged t\n"
          ]
        }
      ],
      "source": [
        "seed = \"all the worlds a stage and all the men and women\"\n",
        "print(generate_text(seed, 400))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "EkP6Z416Qe9q"
      },
      "outputs": [],
      "source": [
        "pickle.dump(model, open(\"shakespeare.pkl\", \"wb\"))"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1Z9zQiZ7MY3t"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}